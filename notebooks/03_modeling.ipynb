{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "814b491d",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f54ed47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix, precision_score, recall_score, roc_auc_score\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "sys.path.append('C:\\\\Coding\\\\customer-churn-prediction\\\\src')\n",
    "from utils import download_telco_churn_dataset, split_test_train\n",
    "from preprocessing import get_preproc\n",
    "\n",
    "RND_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9a12d8",
   "metadata": {},
   "source": [
    "**Getting Preprocessing and Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4902f1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "telco = pd.read_csv(\"../data/raw/WA_Fn-UseC_-Telco-Customer-Churn.csv\")\n",
    "X_train, X_test, y_train, y_test = split_test_train(telco)\n",
    "\n",
    "preprocessing = get_preproc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b260894",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0525d86",
   "metadata": {},
   "source": [
    "**Help Function**\n",
    "\n",
    "Функция для оценки различных моделей на тестовой и тернировочных данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a71fc4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "\n",
    "def fit_and_evaluate(models, cv=10):\n",
    "    # Крафтим пайплайны для каждой модели\n",
    "    pipelines = {}\n",
    "\n",
    "    for name, model in models:\n",
    "        pipelines[name] = (Pipeline([\n",
    "            (\"preproc\", preprocessing),\n",
    "            (\"model\", model)\n",
    "        ]))\n",
    "        \n",
    "    metrics = {}\n",
    "\n",
    "    # Оценивать модели будем по f1 score, но важна нам именно метрика recall для положительного класса\n",
    "    for name, model in pipelines.items():\n",
    "        # Исправляем дисбаланс классов\n",
    "        classes_weights = class_weight.compute_sample_weight(\n",
    "            class_weight='balanced',\n",
    "            y=y_train\n",
    "        )\n",
    "        model.fit(X_train, y_train, model__sample_weight=classes_weights)\n",
    "        \n",
    "        # Predictions on test and train\n",
    "        print(\"\\n\" + f\"Оценка {name}:\")\n",
    "        \n",
    "        roc_auc_train = cross_val_score(\n",
    "            model, X_test, y_test, scoring='roc_auc', cv=cv, n_jobs=-1).mean()\n",
    "        f1_cv = cross_val_score(\n",
    "            model, X_test, y_test, scoring='f1', cv=cv, n_jobs=-1).mean()\n",
    "        \n",
    "        # print(f\"TRAIN ROC-AUC: {roc_auc_train}\")\n",
    "        y_pred_test = model.predict(X_test)\n",
    "\n",
    "        # Metrics evaluating\n",
    "        roc_auc_test = roc_auc_score(y_test, y_pred_test)\n",
    "        # print(f\"TEST ROC-AUC: {roc_auc_test}\")\n",
    "\n",
    "        # Confusion Matrix\n",
    "        cm = confusion_matrix(y_test, y_pred_test)\n",
    "        cm_df = pd.DataFrame(cm,\n",
    "                             index=['Факт: 0', 'Факт: 1'],\n",
    "                             columns=['Прогноз: 0', 'Прогноз: 1'])\n",
    "        print(cm_df)\n",
    "        \n",
    "        metrics[name] = {\n",
    "            'roc_auc_test': roc_auc_test,\n",
    "            'roc_auc_cv': roc_auc_train,\n",
    "            'f1_cv': f1_cv,\n",
    "        }\n",
    "    \n",
    "    sorted_metrics = dict(sorted(metrics.items(), key=lambda item: -item[1]['f1_cv']))\n",
    "    \n",
    "    print(f\"ТОП МОДЕЛЕЙ:\")\n",
    "    for name, metric in sorted_metrics.items():\n",
    "        print(\"\\n\" + f\"{name} : \\nF1: {metric['f1_cv']}\\nAUC: {metric['roc_auc_cv']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe7755b",
   "metadata": {},
   "source": [
    "## Models Comparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b0193fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgbm = LGBMClassifier(random_state=RND_SEED, verbose=-1)\n",
    "\n",
    "lr = LogisticRegression(random_state=RND_SEED, penalty='l2')\n",
    "\n",
    "lin_svc = LinearSVC(C=1, random_state=RND_SEED)\n",
    "\n",
    "gb = GradientBoostingClassifier(random_state=RND_SEED)\n",
    "\n",
    "svc = SVC(C=1, random_state=RND_SEED)\n",
    "\n",
    "rnd_forest = RandomForestClassifier(random_state=RND_SEED, n_jobs=-1)\n",
    "\n",
    "xgb = XGBClassifier(random_state=RND_SEED, n_jobs=-1)\n",
    "\n",
    "models = [\n",
    "    (\"Logistic Regression L2\", lr),\n",
    "    (\"LightGBM\", lgbm),\n",
    "    (\"RND Forest\", rnd_forest),\n",
    "    (\"XGB Classifier\", xgb),\n",
    "    (\"Gradient Boosting\", gb),\n",
    "    (\"Linear SVC\", lin_svc),\n",
    "    (\"SVC\", svc),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f0fc5752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Оценка Logistic Regression L2:\n",
      "         Прогноз: 0  Прогноз: 1\n",
      "Факт: 0         759         276\n",
      "Факт: 1          81         293\n",
      "\n",
      "Оценка LightGBM:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Coding\\customer-churn-prediction\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Прогноз: 0  Прогноз: 1\n",
      "Факт: 0         794         241\n",
      "Факт: 1          91         283\n",
      "\n",
      "Оценка RND Forest:\n",
      "         Прогноз: 0  Прогноз: 1\n",
      "Факт: 0         931         104\n",
      "Факт: 1         197         177\n",
      "\n",
      "Оценка XGB Classifier:\n",
      "         Прогноз: 0  Прогноз: 1\n",
      "Факт: 0         819         216\n",
      "Факт: 1         113         261\n",
      "\n",
      "Оценка Gradient Boosting:\n",
      "         Прогноз: 0  Прогноз: 1\n",
      "Факт: 0         753         282\n",
      "Факт: 1          80         294\n",
      "\n",
      "Оценка Linear SVC:\n",
      "         Прогноз: 0  Прогноз: 1\n",
      "Факт: 0         753         282\n",
      "Факт: 1          82         292\n",
      "\n",
      "Оценка SVC:\n",
      "         Прогноз: 0  Прогноз: 1\n",
      "Факт: 0         773         262\n",
      "Факт: 1          81         293\n",
      "ТОП МОДЕЛЕЙ:\n",
      "\n",
      "Gradient Boosting : \n",
      "F1: 0.5574284635465031\n",
      "AUC: 0.821506052158837\n",
      "\n",
      "RND Forest : \n",
      "F1: 0.5563693061786401\n",
      "AUC: 0.8132436323257733\n",
      "\n",
      "Logistic Regression L2 : \n",
      "F1: 0.5549720188962309\n",
      "AUC: 0.8386088188144907\n",
      "\n",
      "Linear SVC : \n",
      "F1: 0.5539445671142795\n",
      "AUC: 0.835851418810029\n",
      "\n",
      "SVC : \n",
      "F1: 0.5389385604088957\n",
      "AUC: 0.7941406694025498\n",
      "\n",
      "LightGBM : \n",
      "F1: 0.5337907248374962\n",
      "AUC: 0.8063783640367699\n",
      "\n",
      "XGB Classifier : \n",
      "F1: 0.5236461687839126\n",
      "AUC: 0.7980948500876963\n"
     ]
    }
   ],
   "source": [
    "fit_and_evaluate(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c46b27",
   "metadata": {},
   "source": [
    "Непосредственно в этой задаче мне важен `Recall` на положительном класса, то есть процент верно определенных `Churn`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c670839d",
   "metadata": {},
   "source": [
    "## Lin SVC + GB + Logist Regr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cb6db24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from scipy.stats import loguniform, uniform, randint\n",
    "\n",
    "\n",
    "def fine_tuning_models(models_data):\n",
    "    for name, model_data in models_data.items():\n",
    "        models_data[name] = {\n",
    "            \"pipeline\": Pipeline([\n",
    "                (\"preproc\", preprocessing),\n",
    "                (\"model\", model_data[\"model\"]),\n",
    "            ]),\n",
    "            \"param_distrib\": model_data[\"param_disturb\"],\n",
    "        }\n",
    "\n",
    "        f1_losses = cross_val_score(\n",
    "            models_data[name][\"pipeline\"], X_train, y_train, cv=10, n_jobs=-1, scoring='f1')\n",
    "        print(f'{name} f1:\\n{pd.Series(f1_losses).mean()}')\n",
    "        \n",
    "    # Исправляем дисбаланс классов\n",
    "    classes_weights = class_weight.compute_sample_weight(\n",
    "        class_weight='balanced',\n",
    "        y=y_train\n",
    "    )\n",
    "    \n",
    "    print('=' * 50 + \"Tuned models!!!\" + '=' * 50)\n",
    "    \n",
    "    best_models = {}\n",
    "    \n",
    "    for name, model_data in models_data.items():\n",
    "        rnd_search = RandomizedSearchCV(model_data[\"pipeline\"], param_distributions=model_data[\"param_distrib\"], n_iter=50, cv=5, n_jobs=-1, random_state=RND_SEED)\n",
    "        rnd_search.fit(X_train, y_train, model__sample_weight=classes_weights)\n",
    "\n",
    "        f1_losses_cv = cross_val_score(rnd_search.best_estimator_, X_train, y_train, cv=10, n_jobs=-1, scoring='f1')\n",
    "        \n",
    "        print(f'{name} f1:\\n{pd.Series(f1_losses_cv).mean()}')\n",
    "        \n",
    "        best_models[name] = rnd_search.best_estimator_\n",
    "        \n",
    "    return best_models\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e14a773c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_lin_svc = {\n",
    "    \"model__tol\": uniform(1e-6, 1e-4),\n",
    "    \"model__C\": loguniform(0.1, 10),\n",
    "    \"model__fit_intercept\": [True, False],\n",
    "    \"model__intercept_scaling\": loguniform(1, 10),\n",
    "}\n",
    "\n",
    "pd_gb = {\n",
    "    \"model__learning_rate\": loguniform(0.05, 0.1),\n",
    "    \"model__n_estimators\": randint(100, 200),\n",
    "    \"model__max_depth\": randint(3, 5),\n",
    "    \"model__max_features\": ['sqrt', 'log2', None],\n",
    "}\n",
    "\n",
    "pd_lr = [\n",
    "    {\n",
    "        \"model__penalty\": ['l2'],\n",
    "        \"model__tol\": uniform(1e-6, 1e-4),\n",
    "        \"model__C\": loguniform(0.5, 10),\n",
    "        \"model__max_iter\": randint(50, 500),\n",
    "        \"model__solver\": ['lbfgs'],\n",
    "    },\n",
    "    {\n",
    "        \"model__penalty\": ['l2', 'l1'],\n",
    "        \"model__tol\": uniform(1e-6, 1e-4),\n",
    "        \"model__C\": loguniform(0.5, 10),\n",
    "        \"model__max_iter\": randint(50, 500),\n",
    "        \"model__solver\": ['liblinear'],\n",
    "    }\n",
    "]\n",
    "\n",
    "models_data = {\n",
    "    \"Logistic Regression\": {\n",
    "        \"model\": lr,\n",
    "        \"param_disturb\": pd_lr,\n",
    "    },\n",
    "    \"Gradient Boosting\": {\n",
    "        \"model\": gb,\n",
    "        \"param_disturb\": pd_gb,\n",
    "    },\n",
    "    \"Linear SVC\": {\n",
    "        \"model\": lin_svc,\n",
    "        \"param_disturb\": pd_lin_svc,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e85393ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression f1:\n",
      "0.5929170175962092\n",
      "Gradient Boosting f1:\n",
      "0.5813504460806895\n",
      "Linear SVC f1:\n",
      "0.5687812406106663\n",
      "==================================================Tuned models!!!==================================================\n",
      "Logistic Regression f1:\n",
      "0.5924823663382313\n",
      "Gradient Boosting f1:\n",
      "0.5858352880636593\n",
      "Linear SVC f1:\n",
      "0.573080332393418\n"
     ]
    }
   ],
   "source": [
    "best_models = fine_tuning_models(models_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdddf44d",
   "metadata": {},
   "source": [
    "Не улучшилось - выбираем `Logistic Regression`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

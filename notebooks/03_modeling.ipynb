{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "814b491d",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f54ed47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix, precision_score, recall_score, roc_auc_score\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "sys.path.append('C:\\\\Coding\\\\customer-churn-prediction\\\\src')\n",
    "from utils import download_telco_churn_dataset, split_test_train\n",
    "from preprocessing import get_preproc\n",
    "\n",
    "RND_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9a12d8",
   "metadata": {},
   "source": [
    "**Getting Preprocessing and Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4902f1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "telco = pd.read_csv(\"../data/raw/WA_Fn-UseC_-Telco-Customer-Churn.csv\")\n",
    "X_train, X_test, y_train, y_test = split_test_train(telco)\n",
    "\n",
    "preprocessing = get_preproc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b260894",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0525d86",
   "metadata": {},
   "source": [
    "**Help Function**\n",
    "\n",
    "Функция для оценки различных моделей на тестовой и тернировочных данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a71fc4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "\n",
    "def fit_and_evaluate(models, cv=10):\n",
    "    # Крафтим пайплайны для каждой модели\n",
    "    pipelines = {}\n",
    "\n",
    "    for name, model in models:\n",
    "        pipelines[name] = (ImbPipeline([\n",
    "            (\"preproc\", preprocessing.named_steps['preproc']),\n",
    "            (\"smote\", preprocessing.named_steps['smote']),\n",
    "            (\"model\", model)\n",
    "        ]))\n",
    "\n",
    "    metrics = {}\n",
    "\n",
    "    # Оценивать модели будем по roc_auc score\n",
    "    for name, model in pipelines.items():\n",
    "        # Оценим сырые модельки на CV\n",
    "        roc_auc_cv = cross_val_score(\n",
    "            model, X_train, y_train, scoring='roc_auc', cv=cv, n_jobs=-1).mean()\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred_test = model.predict(X_test)\n",
    "\n",
    "        # Metrics evaluating\n",
    "        roc_auc_test = roc_auc_score(y_test, y_pred_test)\n",
    "\n",
    "        metrics[name] = {\n",
    "            'roc_auc_test': roc_auc_test,\n",
    "            'roc_auc_cv': roc_auc_cv,\n",
    "        }\n",
    "\n",
    "    sorted_metrics = dict(\n",
    "        sorted(metrics.items(), key=lambda item: -item[1]['roc_auc_cv']))\n",
    "\n",
    "    print(f\"ТОП МОДЕЛЕЙ по ROC-AUC:\")\n",
    "    for name, metric in sorted_metrics.items():\n",
    "        print(\n",
    "            \"\\n\" + f\"{name} : \\nAUC: {metric['roc_auc_cv']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe7755b",
   "metadata": {},
   "source": [
    "## Models Comparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0193fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgbm = LGBMClassifier(random_state=RND_SEED, verbose=-1)\n",
    "\n",
    "lr = LogisticRegression(random_state=RND_SEED, penalty='l2')\n",
    "\n",
    "lin_svc = LinearSVC(C=1, random_state=RND_SEED)\n",
    "\n",
    "gb = GradientBoostingClassifier(random_state=RND_SEED)\n",
    "\n",
    "svc = SVC(C=1, random_state=RND_SEED)\n",
    "\n",
    "rnd_forest = RandomForestClassifier(random_state=RND_SEED, n_jobs=-1)\n",
    "\n",
    "xgb = XGBClassifier(random_state=RND_SEED, n_jobs=-1)\n",
    "\n",
    "models = [\n",
    "    (\"Logistic Regression L2\", lr),\n",
    "    (\"LightGBM\", lgbm),\n",
    "    (\"RND Forest\", rnd_forest),\n",
    "    (\"XGB Classifier\", xgb),\n",
    "    (\"Gradient Boosting\", gb),\n",
    "    (\"Linear SVC\", lin_svc),\n",
    "    (\"SVC\", svc),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fc5752",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Coding\\customer-churn-prediction\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "fit_and_evaluate(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c46b27",
   "metadata": {},
   "source": [
    "Непосредственно в этой задаче мне важен `Recall` на положительном класса, то есть процент верно определенных `Churn`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c670839d",
   "metadata": {},
   "source": [
    "## Lin SVC + GB + Logist Regr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6db24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import loguniform, uniform, randint\n",
    "\n",
    "\n",
    "def fine_tuning_models(models_data):\n",
    "    for name, model_data in models_data.items():\n",
    "        models_data[name] = {\n",
    "            \"pipeline\": ImbPipeline([\n",
    "                (\"preproc\", preprocessing.named_steps['preproc']),\n",
    "                (\"smote\", preprocessing.named_steps['smote']),\n",
    "                (\"model\", model_data[\"model\"]),\n",
    "            ]),\n",
    "            \"param_distrib\": model_data[\"param_disturb\"],\n",
    "        }\n",
    "\n",
    "        roc_auc_losses = cross_val_score(\n",
    "            models_data[name][\"pipeline\"], X_train, y_train, cv=10, n_jobs=-1, scoring='roc_auc')\n",
    "        print(f'{name} ROC-AUC:\\n{pd.Series(roc_auc_losses).mean()}')\n",
    "\n",
    "    print('=' * 50 + \"Tuned models!!!\" + '=' * 50)\n",
    "\n",
    "    best_models = {}\n",
    "\n",
    "    for name, model_data in models_data.items():\n",
    "        rnd_search = RandomizedSearchCV(model_data[\"pipeline\"], param_distributions=model_data[\"param_distrib\"],\n",
    "                                        n_iter=50, cv=5, n_jobs=-1, random_state=RND_SEED, scoring='roc_auc')\n",
    "        rnd_search.fit(X_train, y_train)\n",
    "\n",
    "        roc_auc_losses_cv = rnd_search.best_score_\n",
    "\n",
    "        print(f'{name} AUC:\\n{pd.Series(roc_auc_losses_cv).mean()}')\n",
    "\n",
    "        best_models[name] = rnd_search.best_estimator_\n",
    "\n",
    "    return best_models\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14a773c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_lin_svc = {\n",
    "    \"model__tol\": uniform(1e-6, 1e-4),\n",
    "    \"model__C\": loguniform(0.01, 5),\n",
    "    \"model__fit_intercept\": [False],\n",
    "}\n",
    "\n",
    "pd_gb = {\n",
    "    \"model__learning_rate\": loguniform(0.05, 0.1),\n",
    "    \"model__n_estimators\": randint(100, 200),\n",
    "    \"model__max_depth\": randint(3, 5),\n",
    "    \"model__max_features\": ['sqrt', 'log2', None],\n",
    "}\n",
    "\n",
    "pd_lr = [\n",
    "    {\n",
    "        \"model__penalty\": ['l2'],\n",
    "        \"model__tol\": uniform(1e-6, 1e-4),\n",
    "        \"model__C\": loguniform(0.01, 2),\n",
    "        \"model__max_iter\": randint(50, 500),\n",
    "        \"model__solver\": ['lbfgs', 'liblinear'],\n",
    "    }\n",
    "]\n",
    "\n",
    "models_data = {\n",
    "    \"Logistic Regression\": {\n",
    "        \"model\": lr,\n",
    "        \"param_disturb\": pd_lr,\n",
    "    },\n",
    "    \"Gradient Boosting\": {\n",
    "        \"model\": gb,\n",
    "        \"param_disturb\": pd_gb,\n",
    "    },\n",
    "    \"Linear SVC\": {\n",
    "        \"model\": lin_svc,\n",
    "        \"param_disturb\": pd_lin_svc,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85393ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models = fine_tuning_models(models_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdddf44d",
   "metadata": {},
   "source": [
    "Тут лучше всего себя показал градиентный бустинг!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a74a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_tuned = best_models[\"Gradient Boosting\"]\n",
    "lr_tuned = best_models[\"Logistic Regression\"]\n",
    "lin_svc_tuned = best_models[\"Linear SVC\"]\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "y_scores = gb_tuned.predict_proba(X_test)[:, 1]\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_scores)\n",
    "average_precision = average_precision_score(y_test, y_scores)\n",
    "\n",
    "# Строим график\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(recall, precision, linewidth=2, label=f'Gradient Boosting (AP = {average_precision:.2f})')\n",
    "\n",
    "y_scores = lr_tuned.predict_proba(X_test)[:, 1]\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_scores)\n",
    "average_precision = average_precision_score(y_test, y_scores)\n",
    "\n",
    "plt.plot(recall, precision, linewidth=2, label=f'Linear Regression (AP = {average_precision:.2f})')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.axis([0, 1, 0, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a936dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve, cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred_cv = cross_val_predict(lr_tuned, X_train, y_train, cv=10, n_jobs=-1)\n",
    "cm_cv = confusion_matrix(y_train, y_pred_cv)\n",
    "\n",
    "cm_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ca229c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "y_pred_proba = gb_tuned.predict_proba(X_test)[:, 1]\n",
    "\n",
    "precision, recall, threshold = precision_recall_curve(y_test, y_pred_proba)\n",
    "\n",
    "optimal_idx = np.argmax(recall > 0.85)\n",
    "optimal_threshold = threshold[optimal_idx]\n",
    "\n",
    "y_pred_otimised = (y_pred_proba >= optimal_threshold).astype(int)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
